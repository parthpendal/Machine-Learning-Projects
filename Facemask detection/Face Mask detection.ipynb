{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce071f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e39a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79aca824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2490e990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['without_mask', 'with_mask']\n",
      "{'without_mask': 1, 'with_mask': 0}\n"
     ]
    }
   ],
   "source": [
    "#accessing dataset for training\n",
    "datapath=\"C:\\\\Users\\\\parth\\\\Downloads\\\\Face-Mask-Detection-master\\\\Face-Mask-Detection-master\\\\dataset\"\n",
    "categories=os.listdir(datapath)\n",
    "print(categories)\n",
    "\n",
    "#Labeling dataset for 1 for 'with mark' and o for 'without mask'\n",
    "label_dict=dict(zip(categories,[1,0]))\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26623894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List for image data\n",
    "image_list=[]\n",
    "image_type=[]\n",
    "from skimage import io\n",
    "\n",
    "#Accessing each image\n",
    "for category in  categories:\n",
    "  folder_path=os.path.join(datapath,category)\n",
    "  \n",
    "  #Getting list of images ina category\n",
    "  img_names=os.listdir(folder_path)\n",
    "  \n",
    "  #Getting image to bits in gray form\n",
    "  for image in img_names:\n",
    "    image_path=os.path.join(folder_path,image)\n",
    "    #img=cv2.imread(image_path)\n",
    "    img = io.imread(image_path)\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) \n",
    "    resized=cv2.resize(gray,(150,150))\n",
    "    image_list.append(resized)\n",
    "    image_type.append(label_dict[category])\n",
    "  #  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbc75efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normanliztion of numbers\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "image_list=np.array(image_list)/255\n",
    "image_list=np.reshape(image_list,(image_list.shape[0],150,150,1))\n",
    "image_type=np.array(image_type)\n",
    "image_type=np_utils.to_categorical(image_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f276d2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model=keras.Sequential([\n",
    "    keras.layers.Conv2D(200,3,padding='same',activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    keras.layers.Conv2D(100,3,padding='same',activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    #keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(50,activation='relu'),\n",
    "    keras.layers.Dense(2,activation='softmax')\n",
    "])\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=opt,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5df86ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into train and test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(image_list,image_type,test_size=0.1,random_state=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dccc3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "14/87 [===>..........................] - ETA: 2:12 - loss: 0.6970 - accuracy: 0.5089"
     ]
    }
   ],
   "source": [
    "#Training a model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')\n",
    "history=model.fit(x_train,y_train,epochs=2,callbacks=[checkpoint],validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b8b6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'],'r',label='training loss')\n",
    "plt.plot(history.history['val_loss'],label='validation loss')\n",
    "plt.xlabel('# epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef2471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'],'r',label='training accuracy')\n",
    "plt.plot(history.history['val_accuracy'],label='validation accuracy')\n",
    "plt.xlabel('# epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ffad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accessing webcam and face detection module\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "model = load_model('model-003.model')\n",
    "\n",
    "#Detecting masks\n",
    "face_clsfr=cv2.CascadeClassifier('C:\\\\Users\\\\parth\\\\anaconda3\\\\Lib\\\\site-packages\\\\cv2\\\\data\\\\haarcascade_frontalface_default.xml')\n",
    "source=cv2.VideoCapture(0)\n",
    "labels_dict={0:'MASK',1:'NO MASK'}\n",
    "color_dict={0:(0,255,0),1:(0,0,255)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0754a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening a webcam and accessing the images\n",
    "while(True):\n",
    "  ret,img=source.read()\n",
    "  face_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "  faces=face_clsfr.detectMultiScale(face_img,1.3,5)\n",
    "\n",
    "  for x,y,w,h in faces:\n",
    "        face_img=face_img[y:y+w,x:x+w]\n",
    "        resized=cv2.resize(face_img,(150,150))\n",
    "        normalized=resized/255.0\n",
    "        reshaped=np.reshape(normalized,(1,150,150,1))\n",
    "        result=model.predict(reshaped)\n",
    "\n",
    "        label=np.argmax(result,axis=1)[0]\n",
    "      \n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),color_dict[label],2)\n",
    "        cv2.rectangle(img,(x,y-40),(x+w,y),color_dict[label],-1)\n",
    "        cv2.putText(img, labels_dict[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "  cv2.imshow('LIVE',img)\n",
    "  key=cv2.waitKey(1)\n",
    "    \n",
    "  if(key==27):\n",
    "    break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "source.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e12da7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
