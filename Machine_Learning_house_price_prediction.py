# -*- coding: utf-8 -*-
"""Advance House Price Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10M6iH5ImjvYnzSTP66n_Oyayg64r4dLO

## Source data: https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data
"""

#Importing necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_squared_error, mean_absolute_error

# Reading train dataset
df_train=pd.read_csv("train.csv")

# Reading test dataset
df_test=pd.read_csv("test.csv")

#Understand size of train and test files
print(df_train.shape)
print(df_test.shape)

#Find out conut of null values in each columns for train dataset
df_train.isnull().sum().head(50)

#Try to see null values with heatmap
sns.heatmap(df_train.isnull(),yticklabels=False,cbar=False,cmap="viridis")

#Find out conut of null values in each columns for test dataset
df_test.isnull().sum().head(50)

# Replacing all the categorical values with mode and quantitative values with mean
df_test["MSZoning"]=df_test["MSZoning"].fillna(df_test["MSZoning"].mode()[0])

df_train["BsmtQual"]=df_train["BsmtQual"].fillna(df_train["BsmtQual"].mode()[0])
df_test["BsmtQual"]=df_test["BsmtQual"].fillna(df_test["BsmtQual"].mode()[0])

df_train["BsmtCond"]=df_train["BsmtCond"].fillna(df_train["BsmtCond"].mode()[0])
df_test["BsmtCond"]=df_test["BsmtCond"].fillna(df_test["BsmtCond"].mode()[0])

df_train["BsmtExposure"]=df_train["BsmtExposure"].fillna(df_train["BsmtExposure"].mode()[0])
df_test["BsmtExposure"]=df_test["BsmtExposure"].fillna(df_test["BsmtExposure"].mode()[0])

df_train["BsmtFinType1"]=df_train["BsmtFinType1"].fillna(df_train["BsmtFinType1"].mode()[0])
df_test["BsmtFinType1"]=df_test["BsmtFinType1"].fillna(df_test["BsmtExposure"].mode()[0])

df_train["BsmtFinType2"]=df_train["BsmtFinType2"].fillna(df_train["BsmtFinType2"].mode()[0])
df_test["BsmtFinType2"]=df_test["BsmtFinType2"].fillna(df_test["BsmtFinType2"].mode()[0])

df_train["BsmtFinSF2"]=df_train["BsmtFinSF2"].fillna(df_train["BsmtFinSF2"].mode()[0])
df_test["BsmtFinSF2"]=df_test["BsmtFinSF2"].fillna(df_test["BsmtFinSF2"].mode()[0])

df_train["Exterior1st"]=df_train["Exterior1st"].fillna(df_train["Exterior1st"].mode()[0])
df_test["Exterior1st"]=df_test["Exterior1st"].fillna(df_test["Exterior1st"].mode()[0])


df_train["Exterior2nd"]=df_train["Exterior2nd"].fillna(df_train["Exterior2nd"].mode()[0])
df_test["Exterior2nd"]=df_test["Exterior2nd"].fillna(df_test["Exterior2nd"].mode()[0])

df_train["MasVnrType"]=df_train["MasVnrType"].fillna(df_train["MasVnrType"].mode()[0])
df_test["MasVnrType"]=df_test["MasVnrType"].fillna(df_test["MasVnrType"].mode()[0])

df_train["BsmtFinType2"]=df_train["BsmtFinType2"].fillna(df_train["BsmtFinType2"].mode()[0])
df_test["BsmtFinType2"]=df_test["BsmtFinType2"].fillna(df_test["BsmtFinType2"].mode()[0])

df_test["Utilities"]=df_test["Utilities"].fillna(df_test["Utilities"].mode()[0])
df_train["Electrical"]=df_train["Electrical"].fillna(df_train["Electrical"].mode()[0])

df_test["Utilities"]=df_test["Utilities"].fillna(df_test["Utilities"].mode()[0])

df_test["BsmtFullBath"]=df_test["BsmtFullBath"].fillna(df_test["BsmtFullBath"].mode()[0])
df_test["BsmtHalfBath"]=df_test["BsmtHalfBath"].fillna(df_test["BsmtHalfBath"].mode()[0])

df_train["GarageType"]=df_train["GarageType"].fillna(df_train["GarageType"].mode()[0])
df_test["GarageType"]=df_test["GarageType"].fillna(df_test["GarageType"].mode()[0])

df_train["GarageYrBlt"]=df_train["GarageYrBlt"].fillna(df_train["GarageYrBlt"].mode()[0])
df_test["GarageYrBlt"]=df_test["GarageYrBlt"].fillna(df_test["GarageYrBlt"].mode()[0])

df_train["GarageFinish"]=df_train["GarageFinish"].fillna(df_train["GarageFinish"].mode()[0])
df_test["GarageFinish"]=df_test["GarageFinish"].fillna(df_test["GarageFinish"].mode()[0])


df_train["GarageCond"]=df_train["GarageCond"].fillna(df_train["GarageCond"].mode()[0])
df_test["GarageCond"]=df_test["GarageCond"].fillna(df_test["GarageCond"].mode()[0])


df_train["GarageQual"]=df_train["GarageQual"].fillna(df_train["GarageQual"].mode()[0])
df_test["GarageQual"]=df_test["GarageQual"].fillna(df_test["GarageQual"].mode()[0])

df_test["KitchenQual"]=df_test["KitchenQual"].fillna(df_test["KitchenQual"].mode()[0])
df_test["Functional"]=df_test["Functional"].fillna(df_test["Functional"].mode()[0])
df_test["GarageCars"]=df_test["GarageCars"].fillna(df_test["GarageCars"].mode()[0])

df_train["LotFrontage"]=df_train["LotFrontage"].fillna(df_train["LotFrontage"].mean())
df_test["LotFrontage"]=df_test["LotFrontage"].fillna(df_test["LotFrontage"].mean())

df_train["BsmtFinSF1"]=df_train["BsmtFinSF1"].fillna(df_train["BsmtFinSF1"].mean())
df_test["BsmtFinSF1"]=df_test["BsmtFinSF1"].fillna(df_test["BsmtFinSF1"].mean())

df_test["BsmtUnfSF"]=df_test["BsmtUnfSF"].fillna(df_test["BsmtUnfSF"].mean())
df_test["TotalBsmtSF"]=df_test["TotalBsmtSF"].fillna(df_test["TotalBsmtSF"].mean())

df_train["MasVnrArea"]=df_train["MasVnrArea"].fillna(df_train["MasVnrArea"].mean())
df_test["MasVnrArea"]=df_test["MasVnrArea"].fillna(df_test["MasVnrArea"].mean())

df_test["GarageArea"]=df_test["GarageArea"].fillna(df_test["GarageArea"].mean())

#Dropping the columns which have large number of records null
df_train.drop(['PoolQC','Fence','MiscFeature','FireplaceQu','Alley'],axis=1,inplace=True)
df_test.drop(['PoolQC','Fence','MiscFeature','FireplaceQu','Alley'],axis=1,inplace=True)

df_train.head()

df_train.head()

#Try to see null values with heatmap
sns.heatmap(df_train.isnull(),yticklabels=False,cbar=False,cmap="viridis")

#Try to see null values with heatmap
sns.heatmap(df_test.isnull(),yticklabels=False,cbar=False,cmap="viridis")

#Listed the columns with categorical values
columns=['MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood',
         'Condition2','BldgType','Condition1','HouseStyle','SaleType',
        'SaleCondition','ExterCond',
         'ExterQual','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',
        'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Heating','HeatingQC',
         'CentralAir',
         'Electrical','KitchenQual','Functional','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive']

#Function to use get dummies for all the columns
def category_onehot_multcols(multcolumns,df):
    for fields in multcolumns:
        df1=pd.get_dummies(df[fields],drop_first=True)
        df.drop([fields],axis=1,inplace=True)
        df=pd.concat([df,df1],axis=1)
    return df

# We will concate train and test first and then get_dummies. 
# IF we perform one hot encoding for train and test speerately we might have different number of columns for train and test. Therefore, we would not be able to 
# perform predictice modeling.
df_train_test=pd.concat([df_train,df_test],axis=0)

df_train_test.head()

df_train_test.shape

# Performing one shot encoding for train and test combined
df_train_test=category_onehot_multcols(columns,df_train_test)

print(df_train_test.shape)
# Removing duplicate columns
df_train_test=df_train_test.loc[:,~df_train_test.columns.duplicated()]

df_train_test.shape

df_train_test.head()

# Segregating Train and test data. Record with salesprice as null will be our test data
df_test=df_train_test[df_train_test.SalePrice.isna() ]
df_test.head()

# Segregating Train and test data. Record with salesprice as not null will be our train data
df_train=df_train_test[df_train_test.SalePrice.notnull() ]
df_train.head()

# creating x_train and y_train
x_train=df_train.drop(["SalePrice","Id"],axis=1)
y_train=df_train[["SalePrice"]]

# Using xgboost model
import xgboost
classifier=xgboost.XGBRegressor()
classifier.fit(x_train,y_train)

#Predicting value of y_train and checking for accuracy
y_train_predict=classifier.predict(x_train)
mean_squared_error(y_train, y_train_predict)
XGBoost_mean_absolute_error=mean_absolute_error(y_train, y_train_predict)

#Predicting values for y_test
x_test=df_test.drop(["SalePrice","Id"],axis=1)
y_test=classifier.predict(x_test)

y_test

#Creating output file with columns ID and sales price
pred=pd.DataFrame(y_test)
final_dataset=pd.concat([df_test["Id"],pred],axis=1)

final_dataset.head()

#writing to the output csv
final_dataset.to_csv("Submission.csv",index=False)

#Trying through linear regression
from sklearn.linear_model import LinearRegression
linear_regressor = LinearRegression()  
linear_regressor.fit(x_train,y_train)
y_train_predict = linear_regressor.predict(x_train)  
mean_squared_error(y_train, y_train_predict)
linear_mean_absolute_error=mean_absolute_error(y_train, y_train_predict)

# Try predicting using deep learning
import tensorflow as tf
from tensorflow import keras

model= keras.Sequential ([
        keras.layers.Dense(128,kernel_initializer='normal', input_shape=(176,),activation='relu'),
        keras.layers.Dense(256,kernel_initializer='normal',activation='relu'),
        keras.layers.Dense(256,kernel_initializer='normal',activation='relu'),
        keras.layers.Dense(256,kernel_initializer='normal',activation='relu'),
        keras.layers.Dense(1,kernel_initializer='normal',activation='linear')
        ])
model.compile (optimizer="adam",
              loss='mse',
                metrics=[ 'mean_squared_logarithmic_error']
              )
model.summary()

model.fit(x_train,y_train,epochs=500)

yp=model.predict(x_train)
yp

#y_train_predict=model.predict(x_test)
Keras_mean_absolute_error= mean_absolute_error(y_train, yp)

#Trying random forest model
from sklearn.ensemble import RandomForestRegressor
model = RandomForestRegressor()
model.fit(x_train,y_train)
# Get the mean absolute error on the validation data
predicted_prices = model.predict(x_train)
random_forest_mae = mean_absolute_error(y_train , predicted_prices)

print("XGBoost Mean absolute Error:              ",XGBoost_mean_absolute_error)
print("Linear regression Mean absolute error:    ",linear_mean_absolute_error)
print("Keras Mean absolute error:                ",Keras_mean_absolute_error )
print('Random forest validation MAE:             ',random_forest_mae)

y_test=model.predict(x_test)
pred=pd.DataFrame(yp)
final_dataset=pd.concat([df_test["Id"],pred],axis=1)
final_dataset.columns=["Id","SalePrice"]
final_dataset.to_csv("Submission.csv",index=False)

